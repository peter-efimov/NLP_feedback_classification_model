{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Машинное обучение при обработке текстов\n",
    "\n",
    "Доступен датасет отзывов в интернет-магазине по критерию \"токсичности\" отзыва. Необходимо построить модель для классификации отзывов. Целевая метрика - f1-мера. Качество по метрике - не менее 0.75.\n",
    "\n",
    "### Описание данных\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pymystem3 import Mystem\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/peterefimov/opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - mkl\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    conda-4.8.5                |           py37_0         3.0 MB  anaconda\n",
      "    mkl-2019.4                 |              233       155.2 MB  anaconda\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       158.2 MB\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  conda              conda-forge::conda-4.8.5-py37hc8dfbb8~ --> anaconda::conda-4.8.5-py37_0\n",
      "  mkl                                             pkgs/main --> anaconda\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "mkl-2019.4           | 155.2 MB  | ##################################### | 100% \n",
      "conda-4.8.5          | 3.0 MB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c anaconda mkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: | \n",
      "Warning: 2 possible package resolutions (only showing differing packages):\n",
      "  - anaconda/osx-64::conda-4.8.5-py37_0\n",
      "  - defaults/osx-64::conda-4.8.5-py37done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/peterefimov/opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - pytorch\n",
      "    - torchvision\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ninja-1.9.0                |   py37h04f5b5a_0          90 KB\n",
      "    pytorch-1.6.0              |          py3.7_0        54.5 MB  pytorch\n",
      "    torchvision-0.7.0          |         py37_cpu         5.8 MB  pytorch\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        60.4 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  ninja              pkgs/main/osx-64::ninja-1.9.0-py37h04f5b5a_0\n",
      "  pytorch            pytorch/osx-64::pytorch-1.6.0-py3.7_0\n",
      "  torchvision        pytorch/osx-64::torchvision-0.7.0-py37_cpu\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "torchvision-0.7.0    | 5.8 MB    | ##################################### | 100% \n",
      "pytorch-1.6.0        | 54.5 MB   | ##################################### | 100% \n",
      "ninja-1.9.0          | 90 KB     | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c pytorch pytorch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/peterefimov/opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - transformers\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    boto3-1.15.2               |     pyh9f0ad1d_0          69 KB  conda-forge\n",
      "    botocore-1.18.2            |     pyh9f0ad1d_0         4.1 MB  conda-forge\n",
      "    certifi-2019.11.28         |           py37_0         148 KB  conda-forge\n",
      "    jmespath-0.10.0            |     pyh9f0ad1d_0          21 KB  conda-forge\n",
      "    regex-2020.7.14            |   py37h60d8a13_0         338 KB  conda-forge\n",
      "    s3transfer-0.3.3           |   py37hc8dfbb8_1          90 KB  conda-forge\n",
      "    sacremoses-0.0.43          |     pyh9f0ad1d_0         430 KB  conda-forge\n",
      "    transformers-2.1.1         |             py_0         162 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         5.3 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  boto3              conda-forge/noarch::boto3-1.15.2-pyh9f0ad1d_0\n",
      "  botocore           conda-forge/noarch::botocore-1.18.2-pyh9f0ad1d_0\n",
      "  jmespath           conda-forge/noarch::jmespath-0.10.0-pyh9f0ad1d_0\n",
      "  regex              conda-forge/osx-64::regex-2020.7.14-py37h60d8a13_0\n",
      "  s3transfer         conda-forge/osx-64::s3transfer-0.3.3-py37hc8dfbb8_1\n",
      "  sacremoses         conda-forge/noarch::sacremoses-0.0.43-pyh9f0ad1d_0\n",
      "  transformers       conda-forge/noarch::transformers-2.1.1-py_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda                        anaconda::conda-4.8.5-py37_0 --> conda-forge::conda-4.8.5-py37hc8dfbb8_1\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  certifi                                         pkgs/main --> conda-forge\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "certifi-2019.11.28   | 148 KB    | ##################################### | 100% \n",
      "sacremoses-0.0.43    | 430 KB    | ##################################### | 100% \n",
      "regex-2020.7.14      | 338 KB    | ##################################### | 100% \n",
      "transformers-2.1.1   | 162 KB    | ##################################### | 100% \n",
      "botocore-1.18.2      | 4.1 MB    | ##################################### | 100% \n",
      "s3transfer-0.3.3     | 90 KB     | ##################################### | 100% \n",
      "boto3-1.15.2         | 69 KB     | ##################################### | 100% \n",
      "jmespath-0.10.0      | 21 KB     | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/peterefimov/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/peterefimov/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/peterefimov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('toxic_comments.csv')\n",
    "# data = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_information_printer(data):\n",
    "    \"\"\"Функция принимает на вход датасет и выводит основную информацию о нём\"\"\"\n",
    "    display(data.head(10))\n",
    "    print('-------- Информация о признаках --------')\n",
    "    display(data.info())\n",
    "    print('-------- Описание числовых признаков --------')\n",
    "    display(data.describe())\n",
    "    print('-------- Информация о пропусках --------')\n",
    "    display(data.isna().sum())\n",
    "    print('-------- Информация о дубликатах --------')\n",
    "    display(data.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0\n",
       "5  \"\\n\\nCongratulations from me as well, use the ...      0\n",
       "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "7  Your vandalism to the Matt Shirvington article...      0\n",
       "8  Sorry if the word 'nonsense' was offensive to ...      0\n",
       "9  alignment on this subject and which are contra...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Информация о признаках --------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Описание числовых признаков --------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.101679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.302226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic\n",
       "count  159571.000000\n",
       "mean        0.101679\n",
       "std         0.302226\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.000000\n",
       "max         1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Информация о пропусках --------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "toxic    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Информация о дубликатах --------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_information_printer(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные загружены, пропусков или дубликатов нет, замена типов данных на текущем этапе не требуется. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лемматизация\n",
    "\n",
    "Лемматизацию будем проводить в библиотеке NLTK, как более быстродейственной. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для оценки работоспособности лемматизатора сделаем небольшой срез из общего датасета\n",
    "data_short = data.sample(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Функция принимает строку и подбирает POS-теги к словам. Возвращает теги\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lem_func(text):\n",
    "    \"\"\"Функция принимает строку и лемматизирует её. Внутри функции ссылка на функцию для \n",
    "    получения тегов слов. Возвращает лемматизированную строку\"\"\"\n",
    "    word_list = nltk.word_tokenize(text)\n",
    "    lemma = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(text)]\n",
    "    return ' '.join(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.5 s, sys: 2.16 s, total: 21.6 s\n",
      "Wall time: 21.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_short['lem_text'] = data_short['text'].apply(lem_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133177</th>\n",
       "      <td>Thanks for saying so! Would that it were done;...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27572</th>\n",
       "      <td>to poor and uncultivated Boing! said Zebedee \\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147302</th>\n",
       "      <td>\"\\n\\n Please stop your disruptive editing. If ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121266</th>\n",
       "      <td>It doesn't matter if YOU think the information...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84214</th>\n",
       "      <td>Blocked and talkpage access revoked.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "133177  Thanks for saying so! Would that it were done;...      0\n",
       "27572   to poor and uncultivated Boing! said Zebedee \\...      0\n",
       "147302  \"\\n\\n Please stop your disruptive editing. If ...      0\n",
       "121266  It doesn't matter if YOU think the information...      0\n",
       "84214                Blocked and talkpage access revoked.      0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_short.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, оценили работоспособность предложенного варианта лемматизации и оценили время работы. Лемматизация всего датасета по пропорции должна занять около получаса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24min 39s, sys: 2min 39s, total: 27min 19s\n",
      "Wall time: 27min 21s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# data['lem_text'] = data['text'].apply(lem_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет лемматизирован. Обработка заняла около получаса, как и предполагалось. Так как в дальнейшем при работе несколько раз умирал Кернел, перезагрузим лемматизированный датасет.\n",
    "Очистим текст от незначащих символов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lem_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation Why the edits make under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>D'aww ! He match this background colour I 'm s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey man , I 'm really not try to edit war . It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>`` More I ca n't make any real suggestion on i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>You , sir , be my hero . Any chance you rememb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic  \\\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1           1  D'aww! He matches this background colour I'm s...      0   \n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4           4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                            lem_text  \n",
       "0  Explanation Why the edits make under my userna...  \n",
       "1  D'aww ! He match this background colour I 'm s...  \n",
       "2  Hey man , I 'm really not try to edit war . It...  \n",
       "3  `` More I ca n't make any real suggestion on i...  \n",
       "4  You , sir , be my hero . Any chance you rememb...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('lemmatized_dataset.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text_eng(text):\n",
    "    \"\"\"Функция приниает текст и удаляет из него все символы, кроме английских букв\"\"\"\n",
    "    new_text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    cleared_text = ' '.join(new_text.split())\n",
    "    return cleared_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.3 ms, sys: 4.17 ms, total: 23.5 ms\n",
      "Wall time: 23.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clear_data = data.copy()\n",
    "clear_data.drop('text', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_data['lem_text'] = clear_data['lem_text'].apply(clear_text_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lem_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation Why the edits make under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>D aww He match this background colour I m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey man I m really not try to edit war It s ju...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  toxic                                           lem_text\n",
       "0           0      0  Explanation Why the edits make under my userna...\n",
       "1           1      0  D aww He match this background colour I m seem...\n",
       "2           2      0  Hey man I m really not try to edit war It s ju..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные очищены от незначащих символов. Теперь разделим данные на обучающую и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((127656, 2), (127656,), (31915, 2), (31915,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(clear_data, test_size = 0.2, random_state = 13)\n",
    "\n",
    "x_train = train.drop('toxic', axis = 1)\n",
    "y_train = train['toxic']\n",
    "x_test = test.drop('toxic', axis = 1)\n",
    "y_test = test['toxic']\n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Балансировка классов\n",
    "Оценим баланс классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['toxic'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные несбалансированны, оценим степень дисбаланса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество токсичных 13063\n",
      "Количество нетоксичных 114593\n",
      "Соотношение 0.113994746625012\n"
     ]
    }
   ],
   "source": [
    "toxic_quantity = (len(train.query('toxic == 1')))\n",
    "nontoxic_quantity = (len(train.query('toxic == 0')))\n",
    "print(f'Количество токсичных {toxic_quantity}')\n",
    "print(f'Количество нетоксичных {nontoxic_quantity}')\n",
    "print(f'Соотношение {toxic_quantity / nontoxic_quantity}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим методы Upsampling и downsampling для балансировки классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling\n",
    "\n",
    "Напишем функцию для выполнения апсемплинга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsampling(data, x_train, y_train, coefficient, target_column):\n",
    "    \"\"\"Функция работает для задачи классификации.\n",
    "    Принимает общий датасет, x_train и y_train, коэффициент компенсации дисбаланса \n",
    "    и название столбца целевого признака.\n",
    "    Возвращает x_train_upsampled и y_train_upsampled\"\"\"\n",
    "    \n",
    "    # Определяем индексы строк, соответствующие разным классам целевого признака\n",
    "    ex_0_index = y_train[y_train == 0].index\n",
    "    ex_1_index = y_train[y_train != 0].index\n",
    "\n",
    "    # Определяем степень дисбаланса\n",
    "    # Присваиваем отдельные датафреймы с классом 0 и 1\n",
    "    ex_0 = data.loc[ex_0_index]\n",
    "    ex_1 = data.loc[ex_1_index]\n",
    "\n",
    "    # Далее определяем, на какую степень будем увеличивать обучающую выборку. \n",
    "    difference = int(coefficient * (ex_0.shape[0] - ex_1.shape[0]))\n",
    "    print(f'Увеличили на {difference} строк')\n",
    "    up_data = ex_1.sample(difference, replace=True).drop([target_column], axis=1)\n",
    "    up_y_data = y_train.loc[up_data.index]\n",
    "\n",
    "    # Объединяем нарощенные данные с обучающей выборкой\n",
    "    import numpy as np\n",
    "    x_train_upsampled = pd.concat([x_train, up_data])\n",
    "    y_train_upsampled = np.hstack((y_train.values, up_y_data.values))\n",
    "    \n",
    "    return x_train_upsampled, y_train_upsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вызовем функцию, коэффициент компенсации дисбаланса подберём эмпирически."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Увеличили на 76147 строк\n"
     ]
    }
   ],
   "source": [
    "x_train_upsampled, y_train_upsampled = upsampling(clear_data, x_train, y_train, 0.75, 'toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((203803, 2), (203803,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверим размерности\n",
    "x_train_upsampled.shape, y_train_upsampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upsampling выполнен."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling\n",
    "\n",
    "Напишем аналогичную фукнцию для даунсемплинга. Его будем делать полностью, без коэффициента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsampling(data, y_train, target_column):\n",
    "    \"\"\"Функция работает для задачи классификации.\n",
    "    Принимает общий датасет, y_train\n",
    "    и название столбца целевого признака.\n",
    "    Возвращает x_train_downsampled и y_train_downsampled\"\"\"\n",
    "\n",
    "    # Определяем индексы строк, соответствующие разным классам целевого признака\n",
    "    ex_0_index = y_train[y_train == 0].index\n",
    "    ex_1_index = y_train[y_train != 0].index\n",
    "    \n",
    "    # Присваиваем отдельные датафреймы с классом 0 и 1\n",
    "    ex_0 = data.loc[ex_0_index]\n",
    "    ex_1 = data.loc[ex_1_index]\n",
    "\n",
    "    down_data = ex_0.sample(ex_1.shape[0]).drop([target_column], axis=1)\n",
    "    down_y_data = y_train.loc[down_data.index]\n",
    "\n",
    "    x_train_downsampled = pd.concat([down_data, ex_1]).drop([target_column], axis=1)\n",
    "    y_train_downsampled = np.hstack((down_y_data.values, y_train[y_train != 0].values))\n",
    "    \n",
    "    return x_train_downsampled, y_train_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_downsampled, y_train_downsampled = downsampling(clear_data, y_train, 'toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26126, 2), (26126,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверим размерности\n",
    "x_train_downsampled.shape, y_train_downsampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downsampling выполнен."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/peterefimov/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Загрузим стоп-слова на английском языке\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь напишем функцию для обучения моделей на кросс-валидации. С её помощью определим подходящий вариант сэмплирования данных и/или гиперпараметры моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_text_learning(model, x_train, y_train):\n",
    "    \"\"\"Функция принимает модель с заданными гиперпараметрами, x_train и y_train.\n",
    "    Обрабатывает x_train в corpus, создаёт массив TFIDF.\n",
    "    Возвращает среднее значение f1-меры по 5 батчам кросс-валидации.\"\"\"    \n",
    "    corpus = x_train['lem_text'].values.astype('U')\n",
    "    count_tf_idf = TfidfVectorizer(stop_words = stopwords)\n",
    "    tf_idf = count_tf_idf.fit_transform(corpus)\n",
    "    score = cross_val_score(model, tf_idf, y_train, cv = 5, scoring = 'f1').mean()  \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим качество логистической регрессии на начальном датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.4 s, sys: 1.55 s, total: 35.9 s\n",
      "Wall time: 23 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7463554239067969"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_text_learning(LogisticRegression(class_weight = 'balanced'), x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь на данных с апсэмплингом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.5 s, sys: 3.7 s, total: 46.2 s\n",
      "Wall time: 32.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9515081558826454"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_text_learning(LogisticRegression(class_weight = 'balanced'), x_train_upsampled, y_train_upsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество заметно улучшилось. Теперь посмотрим уменьшенную выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.72 s, sys: 210 ms, total: 4.93 s\n",
      "Wall time: 3.33 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8835473814143235"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_text_learning(LogisticRegression(class_weight = 'balanced'), x_train_downsampled, y_train_downsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = x_train['lem_text'].values.astype('U')\n",
    "count_tf_idf = TfidfVectorizer(stop_words = stopwords)\n",
    "tf_idf = count_tf_idf.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 11s, sys: 5.76 s, total: 3min 17s\n",
      "Wall time: 3min 20s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7651701979893903"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_text_learning(RandomForestClassifier(class_weight = 'balanced',\n",
    "                    max_depth = 10,\n",
    "                    n_estimators = 100),\n",
    "                    x_train_upsampled, \n",
    "                    y_train_upsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При изучении Random Forest Classifier в данном случае были вручную перебраны несклолько вариантов гиперпараметров, но при увеличении времени обучения условно в 2 раза рост метрики всего на несколько десятых. Провести перебор параметров в GridSearch не получается в виду ограниченных ресурсов компьютера. Так как логистическая регрессия показывает заметно более качественный результат на обучающей выборке, далее лес рассматривать не будем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Примечание про Catboost*\n",
    "\n",
    "*При попытке запустить пробное обучение или grid-search для Catboost несколько раз вылетала ошибка Dead Kernel. После нескольких восстановлений ноутбука попытки его запустить не возобновлял.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование\n",
    "\n",
    "Наилучший результат по качеству и работоспособности показала модель логистической регрессии на нарощенном датасете с коэффициентом компенсации дисбаланса 75%. Эту модель и будем тестировать на предмет достижения целевого уровня метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_text_testing(model, x_train, x_test, y_train, y_test):\n",
    "    \"\"\"Функция принимает модель, x_train, x_test, y_train и y_test.\n",
    "    Преобразует трейн и тест в корпус, затем в массив tf_idf.\n",
    "    Обучает модель, считает предсказания и выводит значение f1-меры\"\"\"\n",
    "    \n",
    "    corpus_train = x_train['lem_text'].values.astype('U')\n",
    "    count_tf_idf = TfidfVectorizer(stop_words = stopwords)\n",
    "    tf_idf = count_tf_idf.fit_transform(corpus_train)\n",
    "    \n",
    "    corpus_test = x_test['lem_text'].values.astype('U')\n",
    "    count_tf_idf = TfidfVectorizer(stop_words = stopwords)\n",
    "    count_tf_idf.fit(corpus_train)\n",
    "    tf_idf_test = count_tf_idf.transform(corpus_test)\n",
    "    \n",
    "    model.fit(tf_idf, y_train)\n",
    "    predictions = model.predict(tf_idf_test)\n",
    "    score = f1_score(y_test, predictions)\n",
    "    \n",
    "    return score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.6 s, sys: 5.17 s, total: 39.7 s\n",
      "Wall time: 36.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7560127499275573"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_text_testing(LogisticRegression(random_state = 13), \n",
    "                   x_train_upsampled, x_test, y_train_upsampled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Целевое значение f1-меры достигнуто. Далее попробуем проработать модель решение задачи через нейросеть BERT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нейросеть BERT\n",
    "\n",
    "Далее применим модель BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lem_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Okay I m go to try and explain this to you aga...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recent edit of Discriminant of an algebraic nu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>After one goat be reveal though there be only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What s wrong with you Get off my talk page if ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arcadia VZW Please consider include a link to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            lem_text  toxic\n",
       "0  Okay I m go to try and explain this to you aga...      0\n",
       "1  Recent edit of Discriminant of an algebraic nu...      0\n",
       "2  After one goat be reveal though there be only ...      0\n",
       "3  What s wrong with you Get off my talk page if ...      0\n",
       "4  Arcadia VZW Please consider include a link to ...      0"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Возьмём 400 сэмплов из лемматизированного и очищенного датасета. В конце сравним результаты.\n",
    "\n",
    "bert_data = clear_data.sample(400).reset_index(drop=True)[['lem_text', 'toxic']]\n",
    "bert_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем токенизатор как объект класса BertTokenizer(). Передадим ему аргумент vocab_file — это файл со словарём, на котором обучалась модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.BertTokenizer(\n",
    "    vocab_file='/Users/peterefimov/Downloads/cased_L-12_H-768_A-12/vocab.txt')\n",
    "\n",
    "tokenized = bert_data['lem_text'].apply(lambda x: tokenizer.encode(x[:512], add_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определяем длину наибольшего вектора в датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим метод padding, чтобы после токенизации длины исходных текстов в корпусе были равными. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101,  3008,   178, ...,     0,     0,     0],\n",
       "       [  101,  2793, 14609, ...,     0,     0,     0],\n",
       "       [  101,  1170,  1141, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  101,  1107,  1155, ...,     0,     0,     0],\n",
       "       [  101,   173, 17252, ...,     0,     0,     0],\n",
       "       [  101, 24585, 13962, ...,     0,     0,     0]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "display(padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём маску, показывающую значащие значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем и конфигурируем модель. Данные конфигуратора берём из открытого источника."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = transformers.BertConfig.from_json_file(\n",
    "    '/Users/peterefimov/Downloads/cased_L-12_H-768_A-12/bert_config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 435779157/435779157 [01:53<00:00, 3834361.84B/s]\n"
     ]
    }
   ],
   "source": [
    "bert_model = transformers.BertModel.from_pretrained(\n",
    "pretrained_model_name_or_path = 'bert-base-cased',\n",
    "    config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = bert_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задаём небольшой размер батча для динамичного отслеживания прогресса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "embeddings = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём эмбеддинги с включённым таймером и полоской прогресса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "201009ee02db4d6ca42f23578b939731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 2min 57s, sys: 15 s, total: 3min 12s\n",
      "Wall time: 1min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "    batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)])\n",
    "    attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "\n",
    "    embeddings.append(batch_embeddings[0][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединяем эмбеддинги с матрицей признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.477557</td>\n",
       "      <td>0.113815</td>\n",
       "      <td>-0.096917</td>\n",
       "      <td>-0.233714</td>\n",
       "      <td>0.063390</td>\n",
       "      <td>0.094934</td>\n",
       "      <td>0.439925</td>\n",
       "      <td>0.214533</td>\n",
       "      <td>0.102198</td>\n",
       "      <td>-1.103622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506750</td>\n",
       "      <td>0.463045</td>\n",
       "      <td>0.004680</td>\n",
       "      <td>-0.119731</td>\n",
       "      <td>0.137669</td>\n",
       "      <td>-0.110459</td>\n",
       "      <td>0.233644</td>\n",
       "      <td>-0.187469</td>\n",
       "      <td>0.415175</td>\n",
       "      <td>0.117096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.680522</td>\n",
       "      <td>0.005659</td>\n",
       "      <td>0.037179</td>\n",
       "      <td>-0.315864</td>\n",
       "      <td>-0.138420</td>\n",
       "      <td>-0.143567</td>\n",
       "      <td>0.190278</td>\n",
       "      <td>-0.002026</td>\n",
       "      <td>-0.168834</td>\n",
       "      <td>-1.096527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.531639</td>\n",
       "      <td>0.268715</td>\n",
       "      <td>-0.156685</td>\n",
       "      <td>-0.059645</td>\n",
       "      <td>0.099499</td>\n",
       "      <td>-0.056560</td>\n",
       "      <td>0.109671</td>\n",
       "      <td>-0.505171</td>\n",
       "      <td>0.277847</td>\n",
       "      <td>0.181735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.495481</td>\n",
       "      <td>-0.038808</td>\n",
       "      <td>-0.080411</td>\n",
       "      <td>-0.035785</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>-0.076255</td>\n",
       "      <td>0.293915</td>\n",
       "      <td>0.021196</td>\n",
       "      <td>0.088449</td>\n",
       "      <td>-1.173879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195202</td>\n",
       "      <td>0.304664</td>\n",
       "      <td>-0.156941</td>\n",
       "      <td>-0.167416</td>\n",
       "      <td>0.030573</td>\n",
       "      <td>0.018894</td>\n",
       "      <td>-0.060493</td>\n",
       "      <td>-0.183485</td>\n",
       "      <td>0.178798</td>\n",
       "      <td>0.034039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.583168</td>\n",
       "      <td>0.138659</td>\n",
       "      <td>-0.122394</td>\n",
       "      <td>-0.187564</td>\n",
       "      <td>-0.095093</td>\n",
       "      <td>0.081158</td>\n",
       "      <td>0.206457</td>\n",
       "      <td>0.037285</td>\n",
       "      <td>-0.046835</td>\n",
       "      <td>-1.211024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167764</td>\n",
       "      <td>0.345412</td>\n",
       "      <td>-0.039917</td>\n",
       "      <td>-0.057574</td>\n",
       "      <td>0.119753</td>\n",
       "      <td>0.159169</td>\n",
       "      <td>0.134730</td>\n",
       "      <td>-0.143873</td>\n",
       "      <td>0.234353</td>\n",
       "      <td>-0.101888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.613386</td>\n",
       "      <td>-0.037629</td>\n",
       "      <td>0.347015</td>\n",
       "      <td>-0.642924</td>\n",
       "      <td>-0.276650</td>\n",
       "      <td>0.060035</td>\n",
       "      <td>0.225953</td>\n",
       "      <td>0.064113</td>\n",
       "      <td>-0.272894</td>\n",
       "      <td>-1.352027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221127</td>\n",
       "      <td>0.367414</td>\n",
       "      <td>-0.122541</td>\n",
       "      <td>-0.105243</td>\n",
       "      <td>0.512391</td>\n",
       "      <td>-0.162107</td>\n",
       "      <td>0.406578</td>\n",
       "      <td>-0.384981</td>\n",
       "      <td>0.437218</td>\n",
       "      <td>0.435328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.477557  0.113815 -0.096917 -0.233714  0.063390  0.094934  0.439925   \n",
       "1  0.680522  0.005659  0.037179 -0.315864 -0.138420 -0.143567  0.190278   \n",
       "2  0.495481 -0.038808 -0.080411 -0.035785  0.022700 -0.076255  0.293915   \n",
       "3  0.583168  0.138659 -0.122394 -0.187564 -0.095093  0.081158  0.206457   \n",
       "4  0.613386 -0.037629  0.347015 -0.642924 -0.276650  0.060035  0.225953   \n",
       "\n",
       "        7         8         9    ...       758       759       760       761  \\\n",
       "0  0.214533  0.102198 -1.103622  ...  0.506750  0.463045  0.004680 -0.119731   \n",
       "1 -0.002026 -0.168834 -1.096527  ...  0.531639  0.268715 -0.156685 -0.059645   \n",
       "2  0.021196  0.088449 -1.173879  ...  0.195202  0.304664 -0.156941 -0.167416   \n",
       "3  0.037285 -0.046835 -1.211024  ...  0.167764  0.345412 -0.039917 -0.057574   \n",
       "4  0.064113 -0.272894 -1.352027  ...  0.221127  0.367414 -0.122541 -0.105243   \n",
       "\n",
       "        762       763       764       765       766       767  \n",
       "0  0.137669 -0.110459  0.233644 -0.187469  0.415175  0.117096  \n",
       "1  0.099499 -0.056560  0.109671 -0.505171  0.277847  0.181735  \n",
       "2  0.030573  0.018894 -0.060493 -0.183485  0.178798  0.034039  \n",
       "3  0.119753  0.159169  0.134730 -0.143873  0.234353 -0.101888  \n",
       "4  0.512391 -0.162107  0.406578 -0.384981  0.437218  0.435328  \n",
       "\n",
       "[5 rows x 768 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.concatenate(embeddings)\n",
    "features = pd.DataFrame(features)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем выборки и обучаем модель логистической регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = bert_data['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test = train_test_split(features, \n",
    "                                                 shuffle=False, \n",
    "                                                 random_state=13, \n",
    "                                                 test_size=0.2)\n",
    "\n",
    "target_train, target_test = train_test_split(target, \n",
    "                                                 shuffle=False, \n",
    "                                                 random_state=13, \n",
    "                                                 test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=13, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(random_state = 13)\n",
    "model.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9285714285714286"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train = model.predict(features_train)\n",
    "f1_score(target_train, predictions_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test = model.predict(features_test)\n",
    "f1_score(target_test, predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40974025974025974\n"
     ]
    }
   ],
   "source": [
    "f1_score_cv = cross_val_score(LogisticRegression(), features, target, scoring = 'f1', cv= 5)\n",
    "print(f1_score_cv.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При рассмотрении модели с признаками, сделанными нейронной сетью BERT были испытаны различные выборки сэмпла, f1-мера проверена на кросс-валидации и на тестовой выборке. Значения меры разнятся от 0.4 до 0.66. Вероятно, это вызвано небольшим размером сэмпла и из-за этого меняющимся балансом классов, который сильно влияет на результат. На обычном компьютере взять значительно больший сэмпл не получится ввиду длительного расчёта эмбеддингов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Наиболее высокую F1-меру на тестовой выборке (0.756) показала логистическая регрессия на датасете, балансировка классов у которого была выполнена методом upsampling.\n",
    "2. Из-за большого количества данных и сложной их структуры мощности гражданского компьютера не хватает для полноценного анализа, отсюда не все модели можно рассмотреть достаточно детально.\n",
    "3. Модель случайного леса показала менее качественный результат в сравнении с регрессией при дОльшем обучении и подборе гиперпараметров.\n",
    "4. Загружена, сконфигурирована и применена нейросеть BERT для создания эмбеддингов и модификации признаков. Качество обученной на этих признаках логистической регрессии нестабильно и не удовлетворяет требованиям. Предположительно, это вызвано недостаточным размером сэмпла, который может быть посчитан на обычном компьютере."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
